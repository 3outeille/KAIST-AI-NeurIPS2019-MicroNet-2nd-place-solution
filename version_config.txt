ver1
cos annealing 600 (4번 주기 함수)
lr min = 0.001

ver2
cos annealing 600 (4번 주기 함수)
init 바꿈
lr min = 0.001

ver3
cos annealing 800 (4번 주기 함수)
init 바꿈
expansion = 2
lr min = 0.0005

ver4
ver2를 pruning rate = 30%로
4번 연속 training

ver5
ver3를 pruningrate을 7.5-15-22.5-30으로 증가시키면서 
4번 iterative training

ver6
[[2, 16, 2, 1],
[2, 32, 1, 2],
[2, 32, 1, 1],
[2, 48, 3, 1],
[2, 72, 1, 2],
[2, 72, 4, 1],
[2, 88, 1, 2],
[2, 88, 2, 1],
[2, 128, 1, 1]]
cos annealing 800 (4번 주기 함수)
lr min = 0.0005

ver7
[2, 24, 1, 1],
[2, 48, 1, 2],
[2, 48, 2, 1],
[2, 88, 1, 2],
[2, 88, 3, 1],
[2, 96, 1, 2],
[2, 96, 1, 1],
[2, 128, 1, 1]]
cos annealing 800 (4번 주기 함수)
lr min = 0.0005
- >Training x

ver8
[[2, 16, 2, 1],
[2, 32, 1, 2],
[2, 32, 1, 1],
[2, 48, 3, 1],
[2, 72, 1, 2],
[2, 72, 4, 1],
[2, 88, 1, 2],
[2, 88, 2, 1],
[2, 128, 1, 1]]
cos annealing 800 (4번 주기 함수)
lr min = 0.0005
-> block bn1, bn2 affine False

ver9
[[2, 16, 2, 1],
[2, 32, 1, 2],
[2, 32, 1, 1],
[2, 48, 3, 1],
[2, 72, 1, 2],
[2, 72, 4, 1],
[2, 88, 1, 2],
[2, 88, 2, 1],
[2, 128, 1, 1]]
cos annealing 800 (4번 주기 함수)
lr min = 0.0005
-> stem bn, block bn1 bn2 affine False
-> 이외의 bn에 대해서도 bias를 없앰.
-> activation 후에 나오는 

ver10
[[2, 16, 2, 1],
[2, 32, 1, 2],
[2, 32, 1, 1],
[2, 48, 3, 1],
[2, 72, 1, 2],
[2, 72, 4, 1],
[2, 88, 1, 2],
[2, 88, 2, 1],
[2, 128, 1, 1]]
cos annealing 800 (4번 주기 함수)
lr min = 0.0005
-> act1의 bn1 affine=False
-> 이후 normalize (0,1)



